<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cauliyang.github.io</id>
    <title>Vince&apos;s Core </title>
    <updated>2019-11-03T08:41:39.479Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://cauliyang.github.io"/>
    <link rel="self" href="https://cauliyang.github.io/atom.xml"/>
    <subtitle>Cherish time, just like cherishing your eyes.</subtitle>
    <logo>https://cauliyang.github.io/images/avatar.png</logo>
    <icon>https://cauliyang.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, Vince&apos;s Core </rights>
    <entry>
        <title type="html"><![CDATA[Bin map ]]></title>
        <id>https://cauliyang.github.io/post/xin-pian-shu-ju-gou-jian-yi-chuan-lian-suo-tu-biao-ji-shai-xuan-liu-cheng</id>
        <link href="https://cauliyang.github.io/post/xin-pian-shu-ju-gou-jian-yi-chuan-lian-suo-tu-biao-ji-shai-xuan-liu-cheng">
        </link>
        <updated>2019-09-09T01:06:33.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>本文记录芯片数据如何筛选，以及使用bin map方法构建遗传图谱。</strong></p>
]]></summary>
        <content type="html"><![CDATA[<p><strong>本文记录芯片数据如何筛选，以及使用bin map方法构建遗传图谱。</strong></p>
<!-- more -->
<p>芯片数据的筛选大致分为以下步骤：</p>
<ol>
<li>
<p><strong>标记QC</strong></p>
<p>1.1	计算标记的检出率，保留&gt;80%，删除缺失率大于20%的标记<br>
<strong>可以适当调整阈值根据自己的数据量</strong></p>
<p>1.2	计算标记的杂合率（如果杂合率很高的情况下，这个SNP可能还是有问题的），但是杂合率的评判标准依据不同群体有所不同，如F2或BC1群体，标记杂合率普遍在40-60%之间，但RIL群体或DH群体就会低很多，可以针对自己的群体，设置合适的阈值</p>
<p>1.3	删除双亲为杂合且是缺失的标记</p>
<p>1.4	计算双亲的无多态性，删除双亲没有多态性的标记</p>
<p>1.5 计算标记的MAF，保留MAF&gt;0.05</p>
<p>1.6 群体内家系基因型根据两亲本更改为 A B H <strong>( 缺失不变）</strong></p>
<p>1.7 删除多拷贝SNP，注释信息中chr hit number&gt;1的标记，这个一般针对那些非常差的标记，<strong>可以忽略此步骤</strong></p>
</li>
<li>
<p><strong>样本QC</strong></p>
<p>2.1	确定标记后，用剩下的标记进行样本质控，计算每个材料的缺失率和杂合率，然后对材料进行筛选</p>
</li>
<li>
<p><strong>卡方测验</strong></p>
<p>3.1 进行卡方测验，计算标记的分离比，删除严重偏分离的标记，这一步也可以在JoinMap，rqtl,AsMap中操作。</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vcftools  Manual]]></title>
        <id>https://cauliyang.github.io/post/vcftools-1</id>
        <link href="https://cauliyang.github.io/post/vcftools-1">
        </link>
        <updated>2019-08-20T04:54:06.000Z</updated>
        <summary type="html"><![CDATA[<p>整理并记录处理VCf文件格式的工具<strong>vcftools</strong>的使用方法，主要用于自己使用。<strong>（侵权，立即删。😊）</strong></p>
]]></summary>
        <content type="html"><![CDATA[<p>整理并记录处理VCf文件格式的工具<strong>vcftools</strong>的使用方法，主要用于自己使用。<strong>（侵权，立即删。😊）</strong></p>
<!-- more -->
<h2 id="1-文件的读入和输出">1. 文件的读入和输出</h2>
<table>
<thead>
<tr>
<th>参数</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>--vcf</td>
<td style="text-align:left">读入vcf类型文件，如不输入其他参数则统计位点，个体信息</td>
</tr>
<tr>
<td>--gzvcf</td>
<td style="text-align:left">读入vcf.gz类型文件，如不输入其他参数则统计位点，个体信息</td>
</tr>
<tr>
<td>--bcf</td>
<td style="text-align:left">读入bcf类型文件，如不输入其他参数则统计位点，个体信息</td>
</tr>
<tr>
<td>--out</td>
<td style="text-align:left">输出文件，需要添加 --recode 参数(重构vcf结果输出INFO列信息）</td>
</tr>
<tr>
<td>--stdout</td>
<td style="text-align:left">输出到标准输出，可配合bgzip，gzip进行压缩</td>
</tr>
<tr>
<td>--recode</td>
<td style="text-align:left">一般与--out一起使用，加入--recode-INFO-all则保留原文件INFO</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>For instance:</strong></p>
<ul>
<li>提取一号染色体上的变异信息到filename文件</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --chr 1 --recode --out filename</code></strong></p>
<ul>
<li>将一号染色体上的变异信息输出到屏幕</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --chr 1 --recode --stdout</code></strong></p>
<ul>
<li>统计个体个数和突变位点总数</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf</code></strong></p>
<ul>
<li>提取染色体A01上的SNP，输出到A01.vcf。<strong>需要带--recode参数</strong></li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --chr A01 --from-bp 1000000 --to-bp 2000000 --recode --recode-INFO-all --out A01.vcf</code></strong></p>
<h2 id="2vcftools-对snp数据过滤">2.vcftools 对snp数据过滤</h2>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>--chr，--not-chr</td>
<td>保留或者去掉某条染色体</td>
</tr>
<tr>
<td>--keep-only-indels，--remove-indels</td>
<td>保留indels，或者去掉indels保留snps</td>
</tr>
<tr>
<td>--indv，--remove-indv</td>
<td>保留或者去掉<strong>某种样品</strong></td>
</tr>
<tr>
<td>--keep，--remove</td>
<td>保留或者去掉<strong>某些样品</strong></td>
</tr>
<tr>
<td>--max-maf</td>
<td>最大等位基因频率</td>
</tr>
<tr>
<td>--maf</td>
<td>最小等位基因频率</td>
</tr>
<tr>
<td>--max-missing</td>
<td><strong>完整度(0-1之间）= 1 - 缺失度</strong></td>
</tr>
<tr>
<td>--minDP</td>
<td>最小深度</td>
</tr>
<tr>
<td>--snps ，--exclude</td>
<td>根据SNP位点过滤</td>
</tr>
<tr>
<td>--min-alleles</td>
<td>最小等位基因数量</td>
</tr>
<tr>
<td>--max-alleles</td>
<td>最大等位基因数量</td>
</tr>
<tr>
<td>--remove-filtered-all</td>
<td>删除FILTER列不是PASS</td>
</tr>
<tr>
<td>--SNPdensity</td>
<td>计算snp在bin内的密度，其后接bin大小</td>
</tr>
<tr>
<td>--extract-FORMAT-info</td>
<td>提取你想要的info，e.g. GT</td>
</tr>
<tr>
<td>--get-INFO</td>
<td>多次提取info，e.g. --get-INFO NS --get-INFO DB</td>
</tr>
</tbody>
</table>
<p>-------------------;</p>
<p><strong>For instance:</strong></p>
<ul>
<li>深度设置为2，每个SNP位点完整度设置为0.7，最小等位基因频率设置为0.05</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --minDP 2 --maf 0.05 --max-missing 0.7 --recode --out o utfile</code></strong></p>
<ul>
<li>从所有样品中提取S1和S2</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --indv S1 --indv S2 --recode --out outfile</code></strong></p>
<ul>
<li>从所有样品中批量提取样品</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --keep sample.list --recode --out outfile</code></strong></p>
<ul>
<li>提取两个等位基因的SNP位点</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --min-alleles 2 --max-alleles 2 --recode --out outfile</code></strong></p>
<h2 id="3vcftools-在群体遗传学中的应用">3.Vcftools 在群体遗传学中的应用</h2>
<blockquote>
<p>计算遗传多样性参数 ： <strong>Fst，π，Tajima'sD</strong> 等</p>
</blockquote>
<h3 id="31-fst计算">3.1 Fst计算</h3>
<pre><code> Fst是衡量群体间分化程度的重要参数，Fst越大，表明群体分化程度越高，受选择程度越高。基于Fst可以进行选择性消除分析。
</code></pre>
<p><strong>For instance:</strong></p>
<ul>
<li>
<p>计算两个群体间fst值，S1.txt和S2.txt是包含了各群体的样品名</p>
<p><strong><code>vcftools --vcf all.vcf --weir-fst-pop S1.txt --weir-fst-pop S2.txt ---fst-window-size 200000 --fst-window-step 100000 --out outfile</code></strong></p>
</li>
</ul>
<h3 id="32-核苷酸多态性统计">3.2 核苷酸多态性统计</h3>
<pre><code>核苷酸多样性π反映了群体的多态性。一般来说受选择程度越高的群体，遗传多样性越单一；野生群体遗传多样性较高。基于π可以进行选择性消除分析。
</code></pre>
<p><strong>For instance:</strong></p>
<ul>
<li>计算群体核苷酸多态性</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --window-pi 1000 --window-pi-step 1000 --out filename</code></strong></p>
<ul>
<li>计算所有单点或所选多点(--positions)的核苷酸多态性</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --site-pi (--positions SNP_list.txt) --out filename</code></strong></p>
<h3 id="33-tajimas-d计算">3.3 Tajima's D计算</h3>
<pre><code>Tajima's D衡量群体中性进化理论的指标，越偏离0，受选择程度越高。
</code></pre>
<p><strong>For instance:</strong></p>
<ul>
<li>计算Tajima's D</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --TajimaD 100000 --out filename</code></strong></p>
<h3 id="34-ld等其他统计参数">3.4 LD等其他统计参数</h3>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>--hap-r2，--geno-r2</td>
<td>LD统计</td>
</tr>
<tr>
<td>--TsTV</td>
<td>SNP转换/颠换统计</td>
</tr>
<tr>
<td>--freq</td>
<td>每个SNP等位基因频率统计</td>
</tr>
<tr>
<td>--counts</td>
<td>每个SNP等位基因个数统计</td>
</tr>
<tr>
<td>--SNPdensity</td>
<td>SNP频率</td>
</tr>
<tr>
<td>--missing-indv</td>
<td>样品等缺失率统计</td>
</tr>
<tr>
<td>--missing-site</td>
<td>SNP缺失率统计</td>
</tr>
<tr>
<td>--depth</td>
<td>个体深度统计</td>
</tr>
<tr>
<td>--site-depth，--site-mean-depth</td>
<td>位点深度，平均深度统计</td>
</tr>
</tbody>
</table>
<h2 id="4其他">4.其他</h2>
<h3 id="41-比较两个vcf文件">4.1 比较两个vcf文件</h3>
<ul>
<li>
<p>比较2个群体的vcf文件，包含多个选项，常用的如<br>
–diff-site<br>
–diff-indv</p>
<p><strong><code>vcftools --gzvcf input_file1.vcf.gz --gzdiff input_file2.vcf.gz --diff-site --out in1_v_in2</code></strong></p>
</li>
</ul>
<h3 id="42-vcf转化plink">4.2 VCF转化plink</h3>
<ul>
<li>vcftools还可以转化多种格式，常用的是转化成plink格式。</li>
</ul>
<p>参数：--012，--IMPUTE，--ldhat-geno，--BEAGLE-GL，--BEAGLE-PL，--plink</p>
<p><strong><code>vcftools --vcf infile.vcf --plink --chr 1 --out output_in_plink</code></strong></p>
<ul>
<li>合并多个vcf文件(也可以使用GATK）</li>
</ul>
<p><strong><code>bcftools merge A.vcf B.vcf &gt; AB.vcf</code></strong></p>
<h3 id="43-其他格式转换">4.3 其他格式转换</h3>
<ul>
<li>--012</li>
<li>--IMPUTE</li>
<li>--ldhat</li>
<li>--ldhat-geno</li>
<li>--BEAGLE-GL</li>
<li>--BEAGLE-PL<br>
---;</li>
</ul>
<p>具体使用方法可以看 <a href="https://vcftools.github.io/man_latest.html"><strong>vcftools说明</strong></a></p>
<h2 id="5总结">5.总结</h2>
<p>本文旨在学习和整理用到的大部分vcftools方法，如果有所纰漏欢迎指正！😊</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[K-means  by Python]]></title>
        <id>https://cauliyang.github.io/post/k-means-cluster-by-python</id>
        <link href="https://cauliyang.github.io/post/k-means-cluster-by-python">
        </link>
        <updated>2019-08-07T14:09:35.000Z</updated>
        <summary type="html"><![CDATA[<p>本篇文章，详细记录如何使用<strong>Python</strong>进行<strong>K-means</strong>，分别用两种方法实现，并记录如何选取K值，并进行可视化评估结果。</p>
]]></summary>
        <content type="html"><![CDATA[<p>本篇文章，详细记录如何使用<strong>Python</strong>进行<strong>K-means</strong>，分别用两种方法实现，并记录如何选取K值，并进行可视化评估结果。</p>
<!-- more --> 
<style>
img{
    width: 80%;
    padding-left: 10%;
}
</style>
<h2 id="1k-means概念介绍">1.<strong>K-means</strong>概念介绍</h2>
<hr>
<h3 id="11-基础概念">1.1 基础概念</h3>
<p><strong>K-means</strong>是一种常用的无监督学习技术，用于在无法知道正确答案下发现数据中隐藏的结构，聚类的目标是在数据中找到自然分组，确保相同集群中元素比不同的集群中元素更加相似。<strong>K-means</strong>方法非常擅长识别球形数据，其缺点是必须指定集群数<strong>K</strong>。如果选择<strong>K</strong>值不当会造成分群效果不好，后文将会介绍两种方法用来评估<strong>K</strong>值及分群效果。并且本文采用两种方式实现<strong>K-means</strong></p>
<ul>
<li>
<p>使用<strong>scikit-learn</strong>模块进行<strong>K-means</strong>聚类分析。</p>
</li>
<li>
<p>从头手写<strong>K-means</strong>方法。</p>
</li>
</ul>
<h3 id="12-算法原理">1.2 算法原理</h3>
<ol>
<li>随机在样本中选取<strong>K</strong>质心作为起始聚类的中心。</li>
<li>将每个样本根据欧式距离分到最近的质心<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span></span></span></span>所在的群中。</li>
<li>将所有样本分群后，重新计算以每个群的中心作为新的质心。</li>
<li>重复2，3 两步，知道质心不再改变，或者达到用户自定义的阈值或最大迭代数。</li>
</ol>
<p><strong>欧式距离</strong>的计算方法为：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><msup><mo>)</mo><mn>2</mn></msup><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo>(</mo><msub><mi>x</mi><mi>j</mi></msub><mo>−</mo><msub><mi>y</mi><mi>j</mi></msub><msup><mo>)</mo><mn>2</mn></msup><mo>=</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>−</mo><mi>y</mi><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">d(x,y)^2 = \sum^{m}_{j = 1}(x_j  - y_j )^2 =  ||x - y||^{2}_{2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathdefault">d</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0651740000000007em;vertical-align:-1.4137769999999998em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000007em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.150216em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span></span></span>代表数据的纬度。</p>
<p>基于欧式距离我们可以把分群的过程描述为一个优化的问题，是一种最小化<strong>群内误差平方和（SSE）<strong>的迭代方法也被称为</strong>群惯性</strong>。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>S</mi><mi>E</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msup><mi>w</mi><mrow><mo>(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo>)</mo></mrow></msup><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msup><mi>x</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>−</mo><msup><mi>μ</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">SSE = \sum^{n}_{i =1 } \sum^{k}_{j=1 } w^{(i,j)}||x^{(i)} - \mu^{(i)}||^{2}_{2} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.2498900000000006em;vertical-align:-1.4137769999999998em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8361130000000006em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>代表样本索引 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span></span></span>代表分群索引</p>
<h2 id="2使用scikit-learn实现k-means方法">2.使用<strong>scikit-learn</strong>实现<strong>K-means</strong>方法</h2>
<hr>
<h3 id="21-创建测试数据并实现算法">2.1 创建测试数据并实现算法</h3>
<p>首先导入所需要的模块：</p>
<pre><code class="language-python"># import module
import numpy as np
from matplotlib import cm
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_samples
</code></pre>
<p>因为二维数据可是简单的绘制在笛卡尔坐标系上，所以生成二维测试数据进行测试：</p>
<pre><code class="language-python"># creat tested data
X, y = make_blobs(n_samples=150, # volume of data 
                  n_features=2, # number of feature 
                  centers=3, # number of centroid
                  cluster_std=0.5,  # distribution of data 
                  shuffle=True,
                  random_state=0)
</code></pre>
<p>绘图查看原始数据：</p>
<pre><code class="language-python"># plot tested data
plt.figure()
plt.scatter(X[:, 0], X[:, 1], c='white', marker='o', edgecolor='black', s=50)
plt.grid()
plt.show()
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://cauliyang.github.io/post-images/1572156791933.png" alt=""></figure>
<p>从图中可以看出创建的测试数据有明显的分群情况,当然在真实的数据当中原始数据可能没有这么理想。我们先在没有推理的情况下确定<strong>K</strong>的值为3。</p>
<pre><code class="language-python"># k-means
km = KMeans(n_clusters=3, # K value 
            init='random',
            n_init=10, # number of repeatation 
            max_iter=300, 
            tol=1e-4, 
            random_state=0)
# predict labels
y_km = km.fit_predict(X)
</code></pre>
<p>我们进行可视化分群结果：</p>
<pre><code class="language-python">#creating function of ploting graph for reusing 
def plot_res(y_km, X, n_cluster):
    # init colors and markers
    colors = ['lightgreen', 'orange', 'lightblue'][:n_cluster]
    markers = ['s', 'o', 'v'][:n_cluster]

    # plot the cluster to comfirm the result of k-meams by sklearn
    for i, (c, m) in enumerate(zip(colors, markers)):
        plt.scatter(X[y_km == i, 0],
                    X[y_km == i, 1],
                    s=50,
                    c=c,
                    marker=m,
                    edgecolor='black',
                    label=f'cluster {i}')

    # plot centroipd of  different clusters
    plt.scatter(km.cluster_centers_[:, 0],
                km.cluster_centers_[:, 1],
                s=250,
                marker='*',
                c='red',
                edgecolors='black',
                label='centroids')
    # plot lengend
    plt.legend(scatterpoints=1)
    # plot grid
    plt.grid()
    plt.show()

</code></pre>
<figure data-type="image" tabindex="2"><img src="https://cauliyang.github.io/post-images/1572158215803.png" alt=""></figure>
<p>可以明显看到分群效果十分明显。不过其中还有许多问题：</p>
<ol>
<li>如何确实<strong>K</strong>值</li>
<li>如何评估分群质量</li>
</ol>
<h3 id="22-如何选取k值">2.2 如何选取<strong>K</strong>值</h3>
<p>下面介绍如何使用肘解法选取合适的<strong>K</strong>值，肘解法目的是找出SSE变化幅度最大的<strong>K</strong>值。使用<code>km.inertia_</code> 即可调出<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>S</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">SSE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span>的值。</p>
<pre><code class="language-python">
distortions = []
# test different  numbers of cluster  to  pick up the best K
for i in range(1, 11):
    km = KMeans(n_clusters=i,
                init='k-means++',
                n_init=10,
                max_iter=300,
                random_state=0)

    km.fit(X)
    distortions.append(km.inertia_)

</code></pre>
<p>测试1-11的<strong>K</strong>值选取，并进行可视化查看结果。</p>
<pre><code class="language-python"># plot the tested result for the best K

plt.plot(range(1, 11), distortions, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Distortion')
plt.show()
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://cauliyang.github.io/post-images/1572160740933.png" alt=""></figure>
<p>从图中我们可以看出在<strong>K</strong>值为3的时候，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>S</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">SSE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span>变化幅度最大，即可得知<strong>K</strong>为3是最优解。</p>
<h3 id="23-如何评估分群的质量">2.3 如何评估分群的质量</h3>
<p>评价聚类质量的一种方法是<strong>轮廓分析</strong>，他可以应用于其他聚类算法，度量其紧密程度。计算轮廓系数的步骤为：</p>
<ol>
<li>计算集群内聚度<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>a</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>，即样本<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">x^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>于集群内所有其他点之间的平均距离。</li>
<li>计算集群与最近集群的分离度<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>b</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">b^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>,即样本<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">x^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>与最近集群内所有样本的平均距离。</li>
<li>计算轮廓系数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>s</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">s^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>，即集群内聚度与集群分离度之差，除以两者中较大的一个。</li>
</ol>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>s</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>=</mo><mfrac><mrow><msup><mi>b</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>−</mo><msup><mi>a</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mrow><mi>max</mi><mo>⁡</mo><mo>{</mo><mrow><msup><mi>b</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo separator="true">,</mo><msup><mi>a</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mo>}</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">s^{(i)} = \frac{b^{(i)} - a^{(i)}}{\max \{{b^{(i)},a^{(i)}}\}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.519em;vertical-align:-0.954em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.565em;"><span style="top:-2.2960000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">max</span><span class="mopen">{</span><span class="mord"><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.814em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.814em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span><span class="mclose">}</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.954em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>轮廓系数的范围在-1到1之间，如果集群分离度和集群内聚度相等，即<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>b</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>=</mo><msup><mi>a</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">b^{(i)}=a^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>。那么轮廓系数为0，如果<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>b</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>&gt;</mo><mo>&gt;</mo><msup><mi>a</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">b^{(i)} &gt;&gt; a^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9270999999999999em;vertical-align:-0.0391em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> 则接近理想的轮廓系数 1 。</p>
<p>可以使用<strong>scikit-learn</strong>中<strong>metric</strong>中的<strong>silhouette_samples</strong>计算样本的轮廓系数。也可以更方便的使用<strong>silhouette_scores</strong>直接计算所有样本的平均轮廓系数。下面显示<strong>K</strong>值基于3的分群结果。</p>
<pre><code class="language-python"># we can use the graph of silhouette to evaluate  result
km = KMeans(n_clusters=3,
            init='k-means++',
            n_init=10,
            max_iter=10,
            tol=1e-04,
            random_state=0)
y_km = km.fit_predict(X)
</code></pre>
<p>绘制轮廓图进行可视化，直观的查看群内轮廓系数。</p>
<pre><code class="language-python"># difining fuction of plot-silhouette for reusing
# plot the graph of silhouette
def plot_sil(y_km, X):
    cluster_lables = np.unique(y_km)
    n_clusters = cluster_lables.shape[0]

    # using function of silhouette in sklearn to get silhouete scores
    silhouette_vals = silhouette_samples(X, y_km, metric='euclidean')

    # plot the graph
    y_ax_lower, y_ax_upper = 0, 0
    yticks = []
    for i, c in enumerate(cluster_lables):
        # get values of  each cluster
        c_silhouette_vals = silhouette_vals[y_km == c] 
        c_silhouette_vals.sort()  # sort value for ploting
        y_ax_upper += len(c_silhouette_vals)
        color = cm.jet(float(i) / n_clusters)
        plt.barh(range(y_ax_lower, y_ax_upper),
                 c_silhouette_vals,
                 height=1.0,
                 edgecolor='none',
                 color=color)
        yticks.append((y_ax_lower + y_ax_upper) / 2)
        y_ax_lower += len(c_silhouette_vals)

    silhouette_avg = np.mean(silhouette_vals)  # get the label of yticks
    plt.axvline(silhouette_avg, color='red',
                linestyle='--')  # plot the avaerage of silhouette
    plt.yticks(yticks, labels=cluster_lables)
    plt.ylabel('Cluster')
    plt.xlabel('Silhouette coefficient')
    plt.show()

</code></pre>
<figure data-type="image" tabindex="4"><img src="https://cauliyang.github.io/post-images/1572162327225.png" alt=""></figure>
<p>从图中我们可以看出轮廓系数不接近于0，且接近于1表明我们的分群结果良好。且在图中轮廓系数的高度代表群内样本数量，如果样本数量相差太大，说明分群效果不是很好。图中虚线表示平均轮廓系数。</p>
<p>为更好的理解轮廓系数的使用，将<strong>K</strong>值变为2，进行聚类。</p>
<pre><code class="language-python">km = KMeans(
    n_clusters=2,  # value of k has changed 
    init='k-means++',
    n_init=10,
    max_iter=10,
    tol=1e-04,
    random_state=0)
y_km = km.fit_predict(X)
</code></pre>
<p>使用上方作图函数，先观察分群效果。</p>
<figure data-type="image" tabindex="5"><img src="https://cauliyang.github.io/post-images/1572162593247.png" alt=""></figure>
<p>从图中可以看出分群效果很差，可视化轮廓系数查看结果。</p>
<figure data-type="image" tabindex="6"><img src="https://cauliyang.github.io/post-images/1572162888640.png" alt=""></figure>
<p>两个群的高度不一致表明分群效果不是很理想，且有的样本轮廓系数极低接近于0。表示分群有很大的问题，需要重新思考<strong>K</strong>值的选取。</p>
<h2 id="3-k-means-from-scratch">3. K-means from scratch</h2>
<p>我们根据算法原理使用<strong>Python</strong>一步步实现<strong>K-means</strong>，首先展示我们所用到的数据集，有关基因在不同条件下处理的表达数据，其中基因数量为样本数量，处理方式为纬度。并且设计为<strong>Terminal</strong>端使用。</p>
<p>终端使用方法为：</p>
<p><code>Usage : python k_mean.py k data max_it (cetroids)</code></p>
<p>其中</p>
<ul>
<li>k_mean.py 为程序脚本</li>
<li>k 为分群数量</li>
<li>data 为原始数据文件</li>
<li>max_it 为最大递归次数</li>
<li>centroids 为初始的质心，用户可以选择提供或者不提供</li>
</ul>
<p>原始数据：</p>
<table>
<thead>
<tr>
<th>gene_expression</th>
<th>treat_1</th>
<th>treat_2</th>
<th>...</th>
</tr>
</thead>
<tbody>
<tr>
<td>g_1</td>
<td>0.2</td>
<td>0.5</td>
<td>...</td>
</tr>
<tr>
<td>g_2</td>
<td>1.4</td>
<td>1.6</td>
<td>...</td>
</tr>
<tr>
<td>...</td>
<td>4.2</td>
<td>2.1</td>
<td>...</td>
</tr>
</tbody>
</table>
<h3 id="31-get-parameters-from-terminal">3.1 Get parameters from terminal</h3>
<p>导入所需的模块</p>
<pre><code class="language-python"># import modules
import sys
import time
import numpy as np
from collections import Counter
from operator import itemgetter
</code></pre>
<p>从终端获取用户传递参数：</p>
<pre><code class="language-python"># defining function for getting parameters from terminal
def get_argv():
    '''
    get the parameters entered by user and return the dictionary parameters
    '''
    # get parameters
    argv_list = sys.argv
    # init parameters
    argv_name = (
        'data',
        'init_cetroids',
        'gene_num',  # numbers of row 
        'ndim',
        'max_it',  # max numbers of  iter
        'k')
    #  determine whether user provide init-centroids according numbers of parameters
    if len(argv_list) == 4:
        # if not provide init-centroid
        _, k, file, max_it = argv_list
        # get information of file
        argv_tuple = get_Cetroid(file, int(k)) + (int(max_it), int(k))
    elif len(argv_list) == 5:
        # if provide init-centroid
        _, k, file, max_it, cetroid_file = argv_list
        # get information
        argv_tuple = get_Cetroid(
            file, int(k), cetroid_file=cetroid_file) + (int(max_it), int(k))
    elif len(argv_list) &lt; 4:
        #  if numbers of parameters is less than  need parameters  then print help
        print('''
            -------------------------------------------------
            Requirement : numpy 

            Usage : python k_mean.py k data max_it (cetroids)

            Result_file : kmeans.out

            Contact : &lt;liyangyang&gt; &lt;yangyangli.vince@gmail.com&gt;

            -------------------------------------------------

            ''')
        sys.exit(0)
    # return dictionary parameters
    return dict(zip(argv_name, argv_tuple))

</code></pre>
<h3 id="32-creating-function-of-report">3.2 Creating function of report</h3>
<pre><code class="language-python"># difining  function of reporting summary 
def summary(kw, tim, kmeanout='kmeans.out'):
    '''
    Create a summary function, count recursive times, run time, etc.。
    '''

    # statistics for each Cluster data
    def print_cluster(kmean=kmeanout):
        # evaluate data
        counter = Counter(np.loadtxt(kmean, dtype=int)[:, 1])
        # produce report
        for clu, num in counter.most_common():
            print(f'    Cluster_{clu} : {num}')

    # creat statistic header
    print('{:-^40}\n'.format('Summary'))
    # print statstic report of each cluster
    print_cluster()
    # print overall information
    print(f'''
    Max_iter_number : {kw['max_it']} 
    Cluster_number  :{kw['k']} 
    Time  : {tim:.2f}s 
    Date  : {time.asctime()}''')
    # creat statistic tial
    print('{:-&lt;40}\n'.format('-'))
</code></pre>
<h3 id="33-calculating-euclidean-distance">3.3 Calculating Euclidean distance</h3>
<pre><code class="language-python"># defining function to calculate Euclidean distance
def eucl_Distance(init_cetroids, piece_data):
    ''' 
    Calculate the Euclidean distance between each data and the centroid
    '''
    distance = np.sqrt(np.sum((init_cetroids - piece_data)**2, axis=1))
    # return euclidean distance
    return distance

</code></pre>
<h3 id="34-getting-centroid-information-and-recursive-function">3.4 Getting centroid information and recursive function</h3>
<pre><code class="language-python">def get_Cetroid(file, k, cetroid_file=None):
    ''' 
    This function is used to get raw data file information: raw data, centroid, data volume, feature dimension
    '''
    # get content of  file
    data = np.loadtxt(file)
    # get information: data volume, feature dimension
    gene_num, ndim = data.shape
    # Determine whether the user provides a centroid, and  randomly if not provided
    if not (cetroid_file):
        # init centroid
        init_cetroids = np.zeros((k, ndim))
        # provied centroid randomly
        for i in range(k):
            index = int(np.random.uniform(0, gene_num))
            init_cetroids[i, :] = data[index, :]
    else:
        # if users provide centroid
        init_cetroids = np.loadtxt(cetroid_file)
    # return information
    return (data, init_cetroids, gene_num, ndim)


    def iter_Cetroid(**argv):
    '''
    Iterative clustering results
    '''
    # get neccessary parameters
    data, init_cetroids, gene_num, ndim, max_it, k = argv.values()
    # init results
    Result = np.zeros((gene_num, 2), dtype=int)
    # grouping data according to Euclidean distance
    for i in range(gene_num):
        # get Euclidean distance
        distance = eucl_Distance(init_cetroids, data[i, :])
        # get the label of shortest distance
        cluster = distance.argmin()
        # grouping
        Result[i, :] = np.array([i, cluster])
    # verify that the results of the iteration are stable and return a new centroid
    Handle, argv['init_cetroids'] = assert_Result(data, init_cetroids, Result,
                                                  k)
    # return informattion
    return Result, Handle.all(), argv, max_it

</code></pre>
<h3 id="35-creating-body-function-and-main-function">3.5 Creating Body function and Main function</h3>
<pre><code class="language-python">def run(arg_dict, it_num=0):
    '''
     the body of  k-means 
    '''
    # perform an iteration and verify that the results are stable
    # then  calculate the new centroid to be returned in dictionary form
    Result, handle, arg_dict, max_it = iter_Cetroid(**arg_dict)
    # determine whether the  condition of end iteration is reached
    if not (handle) and (it_num &lt; max_it):
        # if not reach and the iteration continues
        it_num += 1
        # print numbers of iteration
        print(f'...ing Iter Number :{it_num}')
        # recursive iteration
        run(arg_dict, it_num=it_num)
    # if reach condition
    else:
        # change lable,like change the lables from  0,1,2 to 1,2,3
        Result = Result + 1
        count_1 = Counter(Result[:, 1])
        # save result file
        np.savetxt('kmeans.out', Result, fmt='%d')

def main():
    '''
    the program main function, integrate workflow, and generate reports
    '''
    # get start time
    TIC = time.time()
    # get parameter through terminal
    ARGV = get_argv()
    # running the body function  of k-means
    run(ARGV)
    # get end time
    TOC = time.time()
    # generate report
    summary(ARGV, TOC - TIC)
</code></pre>
<h2 id="4-summary">4. Summary</h2>
<p>本篇文章详细记录两种方式实现<strong>K-means</strong>方法，并且记录如何选取<strong>K</strong>值，如何评估聚类质量。本文最终涉及的代码都会在<a href="https://github.com/cauliyang/Python_book_practice/blob/master/effective_python_practice.ipynb"><strong>Jupyter notebook</strong></a>找到,并且使用<a href="https://github.com/cauliyang/work/tree/master/001_k_mean">脚本程序</a></p>
<p>谢谢观看，欢迎交流！😎</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PCA by Python ]]></title>
        <id>https://cauliyang.github.io/post/pca-by-python-2</id>
        <link href="https://cauliyang.github.io/post/pca-by-python-2">
        </link>
        <updated>2019-07-19T14:07:56.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>This article documents two methods of PCA analysis using Python, and visualizes 2-dimensional results.</strong></p>
]]></summary>
        <content type="html"><![CDATA[<p><strong>This article documents two methods of PCA analysis using Python, and visualizes 2-dimensional results.</strong></p>
<!-- more -->
<style>
img{
    width: 70%;
    padding-left: 1%;
}
</style>
<h2 id="1intrduction">1.Intrduction</h2>
<h3 id="11-whats-pca">1.1 What's PCA?</h3>
<p>When it comes to methods of reducing dimension, PCA that is an unsupervised linear transformation technique, must be not ignored. Moreover, if you want to know the subtle relationships among data set and reduce the computational complexity in downstream analysis, the PCA may be your best choice! Meanwhile, if you would like to present your data in a 2-dimension or 3-dimension coordinate system, and PCA would sweep your problems!</p>
<p>What is reducing dimension? I will show you an example as follows:</p>
<p>First, suppose you have a five-dimensional data set :</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>1-d</th>
<th>2-d</th>
<th>3-d</th>
<th>4-d</th>
<th>5-d</th>
</tr>
</thead>
<tbody>
<tr>
<td>data-1</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
</tr>
<tr>
<td>data-2</td>
<td>6</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td></td>
</tr>
</tbody>
</table>
<p>Then, you could pick up PC1 and PC2 after PCA to reduce dimension for plotting:</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>PC1</th>
<th>PC2</th>
</tr>
</thead>
<tbody>
<tr>
<td>data-1</td>
<td>0.3</td>
<td>0.6</td>
</tr>
<tr>
<td>data-2</td>
<td>0.1</td>
<td>1.2</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
</tbody>
</table>
<p><strong>PC1</strong> and <strong>PC2</strong> are the result obtained through data is projection on the unit vectors, which enable result to have the most biggest variance(means its distribution is wide) and to be irrelevant(covariance = 0).</p>
<h3 id="12-algorithm">1.2 Algorithm</h3>
<ol>
<li>
<p>Normalize <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">d</span></span></span></span> dimension raw data</p>
</li>
<li>
<p>Creat the covariance matrix</p>
</li>
<li>
<p>Calculate the eigenvalues of the covariance matrix and the corresponding eigenvectors</p>
</li>
<li>
<p>The eigenvectors are sorted in the matrix according to the corresponding feature value, and the first k rows are formed into a matrix <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span>.(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>&lt;</mo><mo>&lt;</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">k&lt;&lt;d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">d</span></span></span></span>)</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>=</mo><mi>x</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">Y = xW</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">x</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span> is the result after reducting dimension to k dimension</p>
</li>
</ol>
<p><strong>Note:</strong> There are two prerequisites for conducting PCA</p>
<ul>
<li>
<p>Raw data has no NA</p>
</li>
<li>
<p>The raw data should be normalized</p>
</li>
</ul>
<h2 id="2-pca-from-scratch">2. PCA from scratch</h2>
<ul>
<li>Importing necessary modules</li>
</ul>
<pre><code class="language-python">import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt 
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
</code></pre>
<ul>
<li>Creating raw data</li>
</ul>
<pre><code class="language-python"># get  data set 
df_wine = pd.read_csv(
    'http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',
    header=None,
    engine='python')
# check data
df_wine.head()
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://cauliyang.github.io/post-images/1572760322010.png" alt=""></figure>
<ul>
<li>Creating train and test data set</li>
</ul>
<pre><code class="language-python"># creat train and test data set 
x_train,X_test,y_train,y_test = \
    train_test_split(X,y,test_size = 0.3 , 
                    stratify= y,
                    random_state = 0 )
</code></pre>
<ul>
<li>Standarding the features</li>
</ul>
<pre><code class="language-python"># create standard instance
sc = StandardScaler()
# standard data 
x_train_std = sc.fit_transform(x_train)
x_test_std = sc.fit_transform(x_test)
</code></pre>
<ul>
<li>Creating the covariance matrix and Getting eigenvectors and eigenvalues</li>
</ul>
<p>the calculation of the covriance matrix :</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>σ</mi><mrow><mi>j</mi><mi>k</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo fence="false">(</mo><msubsup><mi>x</mi><mi>j</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup><mo>−</mo><msub><mi>μ</mi><mi>j</mi></msub><mo fence="false">)</mo><mo fence="false">(</mo><msubsup><mi>x</mi><mi>k</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup><mo>−</mo><msub><mi>μ</mi><mi>k</mi></msub><mo fence="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{jk} =  \frac{1}{n} \sum^{n}_{i=1}\bigg(x_{j}^{(i)} - \mu_j\bigg)\bigg(x_{k}^{(i)} - \mu_k\bigg)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size3">)</span></span><span class="mord"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.3986920000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size3">)</span></span></span></span></span></span></p>
<p>Then, using <code>numpy.cov</code> and `numpy.linalg.eig' to get the covariance matrix and eigenvectors respectively</p>
<pre><code class="language-python"># calculate the covariance matrix 
cov_mat = np.cov(x_train_std.T)
# Getting eigenvectors and eigenvalues
eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)
</code></pre>
<p><strong>NOTE:</strong> there are 13 eigenvectors totally, the number of eigenvalues might be not as same as the number of features sometimes.</p>
<p>Firstly, plotting the Variance interpretation ratio, which is obtained through eigenvalue <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\lambda_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> divided by the sum of all the eigenvalues:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><msub><mi>λ</mi><mi>j</mi></msub><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><msub><mi>λ</mi><mi>j</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\lambda_j}{\sum^d_{j=1}\lambda_j}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.686266em;vertical-align:-1.314826em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.120992em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9890079999999999em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.314826em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<pre><code class="language-python"># get sum of all the eigenvalues
tot = sum(eigen_vals)
# get variance interpretation ratio
var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]
cum_var_exp = np.cumsum(var_exp)
</code></pre>
<p>Besides, plotting the result to get in-depth understanding:</p>
<pre><code class="language-python">plt.figure() # creat plot
# creat bar plot
plt.bar(
    range(1, 14),
    var_exp,
    alpha=0.5,
    label='individual explained variance',
)
# creat step plot 
plt.step(range(1, 14),
         cum_var_exp,
         where='mid',
         label='cumulative explained variance')
# add label 
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal component index')
# add legend
plt.legend(loc='best')
# save picture
plt.savefig('pca_index.png', format='png', bbox_inches='tight', dpi=300)
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://cauliyang.github.io/post-images/1572764173795.png" alt=""></figure>
<p>We can conclude that <strong>PC1</strong> only takes account for about 40%. Furthermore, the sum of <strong>PC1</strong> and <strong>PC2</strong> have 60% variance.</p>
<ul>
<li>Selecting the first <strong>k</strong> values to form matrix <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span></li>
</ul>
<pre><code class="language-python"># integrate eigenvalues  and eigenvectors 
eigen_paris = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])
               for i in range(len(eigen_vals))]
# sort according to eigenvalues 
eigen_paris.sort(key=lambda x: x[0], reverse=True)
# pick up the first 2 eigenvalues 
w = np.hstack(
    [eigen_paris[0][1][:, np.newaxis], eigen_paris[1][1][:, np.newaxis]])
# check matrix x 
w
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://cauliyang.github.io/post-images/1572766213478.png" alt=""></figure>
<ul>
<li>Tranforming raw data</li>
</ul>
<pre><code class="language-python"># reduce dimension 
x_train_pca = x_train_std.dot(w)
# check resulted data 
x_train_pca.shape
</code></pre>
<p><code>(124, 2)</code></p>
<p>Then plotting the result and putting the label in terms of original info, but keeping in mind PCA is unsupervised learning skill without labels</p>
<pre><code class="language-python"># init colors and markers 
colors = ['r', 'b', 'g']
markers = ['s', 'x', 'o']
# plot scatter
for l, c, m in zip(np.unique(y_train), colors, markers):
    plt.scatter(x_train_pca[y_train == l, 0],
                x_train_pca[y_train == l, 1],
                c=c,
                label=1,
                marker=m)
# add label and legend 
plt.xlabel('PC 1')
plt.ylabel('PC 2')
plt.legend(loc='lower left')
plt.savefig('distribution.png', format='png', bbox_inches='tight', dpi=300)

</code></pre>
<figure data-type="image" tabindex="4"><img src="https://cauliyang.github.io/post-images/1572766761786.png" alt=""></figure>
<h2 id="3-pca-by-scikit-learn">3. PCA by  scikit-learn</h2>
<p>we can  conduct PCA easily by <strong>sklearn</strong></p>
<ul>
<li>Importing modules</li>
</ul>
<pre><code class="language-python">from sklearn.decomposition import PCA
from matplotlib.colors import ListedColormap
from sklearn.linear_model import LogisticRegression
</code></pre>
<ul>
<li>Defining  function of plot_decision_region</li>
</ul>
<pre><code class="language-python">
def plot_dicision_regions(X, y, classifier, resolution=0.02):
    # init markers and colors 
    markers = ('s', 'x', 'o', '^', 'v')
    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
    cmap = ListedColormap(colors[:len(np.unique(y))])
    # creat info for plot region
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
                           np.arange(x2_min, x2_max, resolution))
    # test classifier's accurate 
    z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
    z = z.reshape(xx1.shape)
    # plot desicion region 
    plt.contourf(xx1, xx2, z, alpha=0.4, cmap=cmap)
    # set x,y length
    plt.xlim(xx1.min(), xx1.max())
    plt.ylim(xx2.min(), xx2.max())
    # plot result 
    for idx, cl in enumerate(np.unique(y)):
        plt.scatter(
            x=X[y == cl, 0],
            y=X[y == cl, 1],
            alpha=0.6,
            color=cmap(idx),
            edgecolor='black',
            marker=markers[idx],
            label=cl,
        )
</code></pre>
<ul>
<li>PCA by sklearn</li>
</ul>
<pre><code class="language-python"># creat pca instance 
pca = PCA(n_components = 2 )
# creat classifier instance 
lr = LogisticRegression()
# reduce dimension for  data set 
x_train_pca = pca.fit_transform(x_train_std)
x_test_pca  = pca.transform(x_test_std)
# classify x_train_pca 
lr.fit(x_train_pca,y_train)
# plot dicision region
plot_dicision_regions(x_train_pca,y_train,classifier=lr)
# add info
plt.xlabel('PC 1')
plt.ylabel('PC 2')
plt.legend(loc='lower left')
plt.show()
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://cauliyang.github.io/post-images/1572767868782.png" alt=""></figure>
<p>We can see that the classifier's accurate is excellent according to actual labels</p>
<p><strong>TIPS</strong>:</p>
<p>You can set <code>n_components = None</code>, and the result would retain all principle components. Moreover, you could call <code>explained_variance_ration_</code> to use variance explanation ratio.</p>
<h2 id="3summary">3.Summary</h2>
<p>All the above are the main content, welcome everybody communicates with me! 🤠</p>
<p><strong>Reference book :</strong> <a href="https://www.amazon.com/dp/B0742K7HYF/ref=sr_1_1?__mk_zh_CN=%E4%BA%9A%E9%A9%AC%E9%80%8A%E7%BD%91%E7%AB%99&amp;crid=27TEKOK8R4TOR&amp;keywords=python+machine+learning+sebastian+raschka&amp;qid=1572770147&amp;s=digital-text&amp;sprefix=python+machine++learning+seb%2Cdigital-text%2C389&amp;sr=1-1">Python marchine learning</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Blog Ideas ]]></title>
        <id>https://cauliyang.github.io/post/bo-ke-xiang-fa</id>
        <link href="https://cauliyang.github.io/post/bo-ke-xiang-fa">
        </link>
        <updated>2019-05-09T00:46:16.000Z</updated>
        <summary type="html"><![CDATA[<p>This Blog record learning process, welcome everyone to communicate with me!😊</p>
]]></summary>
        <content type="html"><![CDATA[<p>This Blog record learning process, welcome everyone to communicate with me!😊</p>
<!-- more -->
<h1 id="ideas">Ideas</h1>
<p>This blog is used as a public note to record my learning process. I also hope to help others~.</p>
<p>If you have an infringement problem, then you can contact me. if it is true ,I will delete it immediately.</p>
]]></content>
    </entry>
</feed>