<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cauliyang.github.io</id>
    <title>Vince&apos;s Tree Hole </title>
    <updated>2020-05-04T09:13:19.363Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://cauliyang.github.io"/>
    <link rel="self" href="https://cauliyang.github.io/atom.xml"/>
    <subtitle>Cherish time, just like cherishing your eyes.</subtitle>
    <logo>https://cauliyang.github.io/images/avatar.png</logo>
    <icon>https://cauliyang.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Vince&apos;s Tree Hole </rights>
    <entry>
        <title type="html"><![CDATA[关于劝退的思考]]></title>
        <id>https://cauliyang.github.io/52R07FPbs/</id>
        <link href="https://cauliyang.github.io/52R07FPbs/">
        </link>
        <updated>2020-04-22T12:28:33.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-自身剖析">1. 自身剖析</h1>
<p>自从我研究生入学之前，我就在思考转专业的事情。客观来说因为自己在高中毕业时没有多花时间去了解专业，只凭借学校的名字而草率选择本科专业，现在回想起来实在可笑。这也让我认识到在人生的关键选择点上千万不能偷懒，而且我的本科生涯可以说是一团糟，有很长一段时间沉溺在游戏中无法自拔，没有学到什么，这固然有专业的因素，我自己的行为也是这件事的原因。如果本科期间有什么能够让我记忆的，我可以毫不避讳地说是我一段残缺的爱情，人会慢慢成长，当时的我没有上进心，没有责任心，陷入虚假的世界中，这是我对自己的反思。现在我开始慢慢认识与规划自己未来的职业规划，研究生两年期间，我付出精力转到交叉学科，现在每每看到劝退文章，我也会胆颤心惊，不过我会思考我走的路是否行的通。在我即将赴美读5年的phd之前，我应该明确我未来是否想从业科研，还是自己多准备学习计算机，数学统计知识转行互联网。我现在的想法是抓住这次全奖机会，在读书期间充分利用时间，弥补自己的不足和科班的短板，尽最大可能学习夯实基础，这样如果我运气好可以从事科研行业，如果运气不好我还可以去工作，这样我有选择，但是人生不是十全十美的，我必须在这两种选择之间有所倾向，目前我的倾向是转行为主，这也需要我和导师沟通，去读的时候不要表现过去勤奋，过去努力，合理安排时间在打下基础方面。</p>
<p>其次在网上获取信息之时，保持一颗平常心，不要过于焦虑，现在传播焦虑的文章太多了，我需要培养一个有独立思考的大脑，我需要看书来获取知识，分辨是非。不过也不能全盘否定。一味的劝退我可能有所偏激，但是不能因为偏激而得出完全否定的结论，因为自己可能懒惰甘于现状不想改变，而下意识地驳斥这种观点，现在我知道我在坑里，我的目标是努力爬出这个坑。一定要保持学习热情，不断汲取知识，我现在已经作出决定，要锻炼心境，不断学习，要有坚实的基础，无论是计算机理论知识，还是编程实践，我始终在路上。并且我要和老师沟通，在读期间做算法开发和优化工作，虽然我的背景发文章困难，不过我要的是一个环境，一个机会，这对我来说已经足够了。</p>
<h1 id="2-生活思考">2. 生活思考</h1>
<h2 id="21-关于生活">2.1 关于生活</h2>
<p>我现在喜欢平静的生活，每天做运动，保持良好的心态，如果未来有时间在压力大的时候可以出去走走，为了让自己未来的日子压力小一些，一定要做到先苦后甜，前期学习工作要扎实，后面慢慢跟进，我不需要我学习的有多块，不过要保证每天我都在学习，不间断，这是我想要的，也是长久学习之道。</p>
<p>戒除一切输出资源消耗型的娱乐活动，避免“时间黑洞”，一定要合理利用时间，不过不用太过极端，适当的看电影放松是可以接受的。养成强大的心态，不畏惧孤独，害怕孤独，要学会拥抱孤独，孤独的时候是我个人成长的最佳时机，一定不能荒废时间，我玩的已经够多了，人生20-30岁我已经快度过一半，未来的时间还要加倍努力，才能实现我想要的生活。我想要未来有实力可以不必生活中的琐碎苦恼，这就要求有经济实力，钱可能很俗，但我要实现人生目标，我就必须拥有它，为我未来的家遮风挡雨。</p>
<h2 id="22-关于感情">2.2 关于感情</h2>
<p>自从我记事以来，我从小离家学习，父母给我的关爱不多，慢慢养成我对家不是特别的眷恋，对亲情，感情后知后觉。从小我就不是一个听话的小孩，我从小学玩到高中，从高中玩到大学，不过我不为我的过去而后悔，一是因为后悔和冲动解决不了任何问题，只会让我陷入到情绪当中，二是我的过去塑造了我，无论过去的好是坏，都是我的组成部分，我要坦然接受，并且着眼与未来，把握时间，少说话，多做事。有人说过于深情是对自己的不负责任，我是过于深情的人吗？在我看来可能是的，也可能不是。我感觉是因为我还会想起她，我感觉不是因为我和她相处很长时间，我忘不看起来也很正常。我不知道爱情是什么，现在的人都很现实，我有一些害怕和恐惧，但我始终相信是有爱情存在的。不过我还会想两个人在一起久了，势必会丧失当初的感觉，相互扶持的感觉应该也不错。</p>
<p>总之，我不了解感情，我现在对待感情就随缘吧，不主动，主要关注我的学业，生活总要继续。絮絮叨叨说了这么多全都是有感而发，起到剖析自己和反思自己的作用，下次我希望写的更加深刻，揭示我内心最黑暗的一面，希望多年以后在看别有一番风味！</p>
<p>yangli 书于 2020年4月22日</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning of Data Structure and Algorithm]]></title>
        <id>https://cauliyang.github.io/cNegnaeIm/</id>
        <link href="https://cauliyang.github.io/cNegnaeIm/">
        </link>
        <updated>2020-04-16T17:33:49.000Z</updated>
        <summary type="html"><![CDATA[<p>本系列记录我学习北大陈斌老师的<a href="https://www.bilibili.com/video/BV1V7411M7YV">数据结构和算法</a>的过程。</p>
]]></summary>
        <content type="html"><![CDATA[<p>本系列记录我学习北大陈斌老师的<a href="https://www.bilibili.com/video/BV1V7411M7YV">数据结构和算法</a>的过程。</p>
<!-- more -->
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[生活随想 ]]></title>
        <id>https://cauliyang.github.io/9jaKMB68a/</id>
        <link href="https://cauliyang.github.io/9jaKMB68a/">
        </link>
        <updated>2020-04-15T14:49:04.000Z</updated>
        <content type="html"><![CDATA[<p>自从疫情开始以来，已足足在家3月有余。在家的生活状态和学校是完全不一样的，这篇文章用做总结并且计划后面的事情，用以勉励自己。  现在是凌晨1点，在我费很大功夫才将我的博客域名调试好，未来5年我的blog的地址是 yangyangli.top，欢迎大家对我写的零零散散提出建议，我也同时修炼下写作的功底。 言归正传，未来不知道还要在家待多久，我目前心中有几个工作要攻克，下面我整理列出：</p>
<ol>
<li>首先我要完成我的毕业论文的写作工作，并且调整好插图和论文相应格式。</li>
<li>其次我应该完成北大陈斌老师的<a href="https://www.bilibili.com/video/BV1V7411M7YV"><strong>数据结构和算法</strong></a>，为以后的科研和工作打下坚实的基础，并且在我的博客记录学习过程。</li>
<li>保持运动，每天进行跑步和跳绳，并且开始调整作息时间，保证早睡早起。</li>
</ol>
<p>在未来一段时间，尽力将这些做好， 下面让我谈一些对生活和自我的反思。</p>
<hr>
<p>我发现每当我在家的时候，我对时间的把握和敏感度就变得很差，我始终在思考我在追寻什么，我是否走在一条正确的道路上，这3个月对我思想改变最大的方面当属对国家和政党的认识，在我上高中的时候，我有一个天天给我们宣传反对党和国家的语文老师，直到我大三的时候我还认为他说的很对，可见我这三年真的是不学无术，对这种问题和别人的煽动轻易就接受，并没有任何的调查和取证，不过他对我影响还是巨大的，我一直记得</p>
<blockquote>
<p>你崇拜一个人是因为不了解他</p>
</blockquote>
<p>我深以为然，因为还有一句话和其有异曲同工之妙</p>
<blockquote>
<p>枕边无美女，身边无伟人</p>
</blockquote>
<p>这使我每当遇到一个很厉害的人时候，不禁去想是什么成就了Ta，我可不可以掌握这种方法。但是如果未来我顺利去美国求学，我的立场又如何呢？我想我的思想出现了动摇，因为我在思考这个问题，这证明我的想法并不是一成不变的，我想去了解这个世界，多多看书是一个捷径，吸取别人的经验和看世界的方式，来寻找自己的内心中所追求的东西。</p>
<hr>
<p>这就是我胡思乱想的结果，我想到就写到哪，放飞自我，若干年回头看会不会别有一番风味呢？下面我想谈谈最近对自己年龄的思考，我是不是被网络裹挟对自己的年龄开始焦虑了呢？我是在挥霍我的青春吗？我该大胆的追寻心中的人和物吗？</p>
<p>答案是不应该，我始终坚信目标如一，投入12分心血，即使路上需要我放弃一些东西。希望我坚持在我的博客下胡言乱语！ 这篇就写到这吧，我要休息了，晚安，如果你在看的话！ 😜</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[T-SNE by Python]]></title>
        <id>https://cauliyang.github.io/t-sne-by-python/</id>
        <link href="https://cauliyang.github.io/t-sne-by-python/">
        </link>
        <updated>2019-10-03T14:11:09.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>This note records T-SNE by Python and  the  differences between  PCA and T-SNE</strong></p>
]]></summary>
        <content type="html"><![CDATA[<p><strong>This note records T-SNE by Python and  the  differences between  PCA and T-SNE</strong></p>
<!-- more -->
<p>I am writing......</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bin map ]]></title>
        <id>https://cauliyang.github.io/xin-pian-shu-ju-gou-jian-yi-chuan-lian-suo-tu-biao-ji-shai-xuan-liu-cheng/</id>
        <link href="https://cauliyang.github.io/xin-pian-shu-ju-gou-jian-yi-chuan-lian-suo-tu-biao-ji-shai-xuan-liu-cheng/">
        </link>
        <updated>2019-09-09T01:06:33.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>本文记录芯片数据如何筛选，以及使用bin map方法构建遗传图谱。</strong></p>
]]></summary>
        <content type="html"><![CDATA[<p><strong>本文记录芯片数据如何筛选，以及使用bin map方法构建遗传图谱。</strong></p>
<!-- more -->
<p>芯片数据的筛选大致分为以下步骤：</p>
<ol>
<li>
<p><strong>标记QC</strong></p>
<p>1.1	计算标记的检出率，保留&gt;80%，删除缺失率大于20%的标记<br>
<strong>可以适当调整阈值根据自己的数据量</strong></p>
<p>1.2	计算标记的杂合率（如果杂合率很高的情况下，这个SNP可能还是有问题的），但是杂合率的评判标准依据不同群体有所不同，如F2或BC1群体，标记杂合率普遍在40-60%之间，但RIL群体或DH群体就会低很多，可以针对自己的群体，设置合适的阈值</p>
<p>1.3	删除双亲为杂合且是缺失的标记</p>
<p>1.4	计算双亲的无多态性，删除双亲没有多态性的标记</p>
<p>1.5 计算标记的MAF，保留MAF&gt;0.05</p>
<p>1.6 群体内家系基因型根据两亲本更改为 A B H <strong>( 缺失不变）</strong></p>
<p>1.7 删除多拷贝SNP，注释信息中chr hit number&gt;1的标记，这个一般针对那些非常差的标记，<strong>可以忽略此步骤</strong></p>
</li>
<li>
<p><strong>样本QC</strong></p>
<p>2.1	确定标记后，用剩下的标记进行样本质控，计算每个材料的缺失率和杂合率，然后对材料进行筛选</p>
</li>
<li>
<p><strong>卡方测验</strong></p>
<p>3.1 进行卡方测验，计算标记的分离比，删除严重偏分离的标记，这一步也可以在JoinMap，rqtl,AsMap中操作。</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vcftools  Manual]]></title>
        <id>https://cauliyang.github.io/vcftools-1/</id>
        <link href="https://cauliyang.github.io/vcftools-1/">
        </link>
        <updated>2019-08-20T04:54:06.000Z</updated>
        <summary type="html"><![CDATA[<p>整理并记录处理VCf文件格式的工具<strong>vcftools</strong>的使用方法，主要用于自己使用。<strong>（侵权，立即删。😊）</strong></p>
]]></summary>
        <content type="html"><![CDATA[<p>整理并记录处理VCf文件格式的工具<strong>vcftools</strong>的使用方法，主要用于自己使用。<strong>（侵权，立即删。😊）</strong></p>
<!-- more -->
<h2 id="1-文件的读入和输出">1. 文件的读入和输出</h2>
<table>
<thead>
<tr>
<th>参数</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>--vcf</td>
<td style="text-align:left">读入vcf类型文件，如不输入其他参数则统计位点，个体信息</td>
</tr>
<tr>
<td>--gzvcf</td>
<td style="text-align:left">读入vcf.gz类型文件，如不输入其他参数则统计位点，个体信息</td>
</tr>
<tr>
<td>--bcf</td>
<td style="text-align:left">读入bcf类型文件，如不输入其他参数则统计位点，个体信息</td>
</tr>
<tr>
<td>--out</td>
<td style="text-align:left">输出文件，需要添加 --recode 参数(重构vcf结果输出INFO列信息）</td>
</tr>
<tr>
<td>--stdout</td>
<td style="text-align:left">输出到标准输出，可配合bgzip，gzip进行压缩</td>
</tr>
<tr>
<td>--recode</td>
<td style="text-align:left">一般与--out一起使用，加入--recode-INFO-all则保留原文件INFO</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>For instance:</strong></p>
<ul>
<li>提取一号染色体上的变异信息到filename文件</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --chr 1 --recode --out filename</code></strong></p>
<ul>
<li>将一号染色体上的变异信息输出到屏幕</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --chr 1 --recode --stdout</code></strong></p>
<ul>
<li>统计个体个数和突变位点总数</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf</code></strong></p>
<ul>
<li>提取染色体A01上的SNP，输出到A01.vcf。<strong>需要带--recode参数</strong></li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --chr A01 --from-bp 1000000 --to-bp 2000000 --recode --recode-INFO-all --out A01.vcf</code></strong></p>
<h2 id="2vcftools-对snp数据过滤">2.vcftools 对snp数据过滤</h2>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>--chr，--not-chr</td>
<td>保留或者去掉某条染色体</td>
</tr>
<tr>
<td>--keep-only-indels，--remove-indels</td>
<td>保留indels，或者去掉indels保留snps</td>
</tr>
<tr>
<td>--indv，--remove-indv</td>
<td>保留或者去掉<strong>某种样品</strong></td>
</tr>
<tr>
<td>--keep，--remove</td>
<td>保留或者去掉<strong>某些样品</strong></td>
</tr>
<tr>
<td>--max-maf</td>
<td>最大等位基因频率</td>
</tr>
<tr>
<td>--maf</td>
<td>最小等位基因频率</td>
</tr>
<tr>
<td>--max-missing</td>
<td><strong>完整度(0-1之间）= 1 - 缺失度</strong></td>
</tr>
<tr>
<td>--minDP</td>
<td>最小深度</td>
</tr>
<tr>
<td>--snps ，--exclude</td>
<td>根据SNP位点过滤</td>
</tr>
<tr>
<td>--min-alleles</td>
<td>最小等位基因数量</td>
</tr>
<tr>
<td>--max-alleles</td>
<td>最大等位基因数量</td>
</tr>
<tr>
<td>--remove-filtered-all</td>
<td>删除FILTER列不是PASS</td>
</tr>
<tr>
<td>--SNPdensity</td>
<td>计算snp在bin内的密度，其后接bin大小</td>
</tr>
<tr>
<td>--extract-FORMAT-info</td>
<td>提取你想要的info，e.g. GT</td>
</tr>
<tr>
<td>--get-INFO</td>
<td>多次提取info，e.g. --get-INFO NS --get-INFO DB</td>
</tr>
</tbody>
</table>
<p>-------------------;</p>
<p><strong>For instance:</strong></p>
<ul>
<li>深度设置为2，每个SNP位点完整度设置为0.7，最小等位基因频率设置为0.05</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --minDP 2 --maf 0.05 --max-missing 0.7 --recode --out o utfile</code></strong></p>
<ul>
<li>从所有样品中提取S1和S2</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --indv S1 --indv S2 --recode --out outfile</code></strong></p>
<ul>
<li>从所有样品中批量提取样品</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --keep sample.list --recode --out outfile</code></strong></p>
<ul>
<li>提取两个等位基因的SNP位点</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --min-alleles 2 --max-alleles 2 --recode --out outfile</code></strong></p>
<h2 id="3vcftools-在群体遗传学中的应用">3.Vcftools 在群体遗传学中的应用</h2>
<blockquote>
<p>计算遗传多样性参数 ： <strong>Fst，π，Tajima'sD</strong> 等</p>
</blockquote>
<h3 id="31-fst计算">3.1 Fst计算</h3>
<pre><code> Fst是衡量群体间分化程度的重要参数，Fst越大，表明群体分化程度越高，受选择程度越高。基于Fst可以进行选择性消除分析。
</code></pre>
<p><strong>For instance:</strong></p>
<ul>
<li>
<p>计算两个群体间fst值，S1.txt和S2.txt是包含了各群体的样品名</p>
<p><strong><code>vcftools --vcf all.vcf --weir-fst-pop S1.txt --weir-fst-pop S2.txt ---fst-window-size 200000 --fst-window-step 100000 --out outfile</code></strong></p>
</li>
</ul>
<h3 id="32-核苷酸多态性统计">3.2 核苷酸多态性统计</h3>
<pre><code>核苷酸多样性π反映了群体的多态性。一般来说受选择程度越高的群体，遗传多样性越单一；野生群体遗传多样性较高。基于π可以进行选择性消除分析。
</code></pre>
<p><strong>For instance:</strong></p>
<ul>
<li>计算群体核苷酸多态性</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --window-pi 1000 --window-pi-step 1000 --out filename</code></strong></p>
<ul>
<li>计算所有单点或所选多点(--positions)的核苷酸多态性</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --site-pi (--positions SNP_list.txt) --out filename</code></strong></p>
<h3 id="33-tajimas-d计算">3.3 Tajima's D计算</h3>
<pre><code>Tajima's D衡量群体中性进化理论的指标，越偏离0，受选择程度越高。
</code></pre>
<p><strong>For instance:</strong></p>
<ul>
<li>计算Tajima's D</li>
</ul>
<p><strong><code>vcftools --vcf infile.vcf --TajimaD 100000 --out filename</code></strong></p>
<h3 id="34-ld等其他统计参数">3.4 LD等其他统计参数</h3>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>--hap-r2，--geno-r2</td>
<td>LD统计</td>
</tr>
<tr>
<td>--TsTV</td>
<td>SNP转换/颠换统计</td>
</tr>
<tr>
<td>--freq</td>
<td>每个SNP等位基因频率统计</td>
</tr>
<tr>
<td>--counts</td>
<td>每个SNP等位基因个数统计</td>
</tr>
<tr>
<td>--SNPdensity</td>
<td>SNP频率</td>
</tr>
<tr>
<td>--missing-indv</td>
<td>样品等缺失率统计</td>
</tr>
<tr>
<td>--missing-site</td>
<td>SNP缺失率统计</td>
</tr>
<tr>
<td>--depth</td>
<td>个体深度统计</td>
</tr>
<tr>
<td>--site-depth，--site-mean-depth</td>
<td>位点深度，平均深度统计</td>
</tr>
</tbody>
</table>
<h2 id="4其他">4.其他</h2>
<h3 id="41-比较两个vcf文件">4.1 比较两个vcf文件</h3>
<ul>
<li>
<p>比较2个群体的vcf文件，包含多个选项，常用的如<br>
–diff-site<br>
–diff-indv</p>
<p><strong><code>vcftools --gzvcf input_file1.vcf.gz --gzdiff input_file2.vcf.gz --diff-site --out in1_v_in2</code></strong></p>
</li>
</ul>
<h3 id="42-vcf转化plink">4.2 VCF转化plink</h3>
<ul>
<li>vcftools还可以转化多种格式，常用的是转化成plink格式。</li>
</ul>
<p>参数：--012，--IMPUTE，--ldhat-geno，--BEAGLE-GL，--BEAGLE-PL，--plink</p>
<p><strong><code>vcftools --vcf infile.vcf --plink --chr 1 --out output_in_plink</code></strong></p>
<ul>
<li>合并多个vcf文件(也可以使用GATK）</li>
</ul>
<p><strong><code>bcftools merge A.vcf B.vcf &gt; AB.vcf</code></strong></p>
<h3 id="43-其他格式转换">4.3 其他格式转换</h3>
<ul>
<li>--012</li>
<li>--IMPUTE</li>
<li>--ldhat</li>
<li>--ldhat-geno</li>
<li>--BEAGLE-GL</li>
<li>--BEAGLE-PL<br>
---;</li>
</ul>
<p>具体使用方法可以看 <a href="https://vcftools.github.io/man_latest.html"><strong>vcftools说明</strong></a></p>
<h2 id="5总结">5.总结</h2>
<p>本文旨在学习和整理用到的大部分vcftools方法，如果有所纰漏欢迎指正！😊</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[K-means  by Python]]></title>
        <id>https://cauliyang.github.io/k-means-cluster-by-python/</id>
        <link href="https://cauliyang.github.io/k-means-cluster-by-python/">
        </link>
        <updated>2019-08-07T14:09:35.000Z</updated>
        <summary type="html"><![CDATA[<p>本篇文章，详细记录如何使用<strong>Python</strong>进行<strong>K-means</strong>，分别用两种方法实现，并记录如何选取K值，并进行可视化评估结果。</p>
]]></summary>
        <content type="html"><![CDATA[<p>本篇文章，详细记录如何使用<strong>Python</strong>进行<strong>K-means</strong>，分别用两种方法实现，并记录如何选取K值，并进行可视化评估结果。</p>
<!-- more --> 
<style>
img{
    width: 80%;
    padding-left: 10%;
}
</style>
<h2 id="1k-means概念介绍">1.<strong>K-means</strong>概念介绍</h2>
<hr>
<h3 id="11-基础概念">1.1 基础概念</h3>
<p><strong>K-means</strong>是一种常用的无监督学习技术，用于在无法知道正确答案下发现数据中隐藏的结构，聚类的目标是在数据中找到自然分组，确保相同集群中元素比不同的集群中元素更加相似。<strong>K-means</strong>方法非常擅长识别球形数据，其缺点是必须指定集群数<strong>K</strong>。如果选择<strong>K</strong>值不当会造成分群效果不好，后文将会介绍两种方法用来评估<strong>K</strong>值及分群效果。并且本文采用两种方式实现<strong>K-means</strong></p>
<ul>
<li>
<p>使用<strong>scikit-learn</strong>模块进行<strong>K-means</strong>聚类分析。</p>
</li>
<li>
<p>从头手写<strong>K-means</strong>方法。</p>
</li>
</ul>
<h3 id="12-算法原理">1.2 算法原理</h3>
<ol>
<li>随机在样本中选取<strong>K</strong>质心作为起始聚类的中心。</li>
<li>将每个样本根据欧式距离分到最近的质心<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span></span></span></span>所在的群中。</li>
<li>将所有样本分群后，重新计算以每个群的中心作为新的质心。</li>
<li>重复2，3 两步，知道质心不再改变，或者达到用户自定义的阈值或最大迭代数。</li>
</ol>
<p><strong>欧式距离</strong>的计算方法为：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><msup><mo>)</mo><mn>2</mn></msup><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo>(</mo><msub><mi>x</mi><mi>j</mi></msub><mo>−</mo><msub><mi>y</mi><mi>j</mi></msub><msup><mo>)</mo><mn>2</mn></msup><mo>=</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>−</mo><mi>y</mi><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">d(x,y)^2 = \sum^{m}_{j = 1}(x_j  - y_j )^2 =  ||x - y||^{2}_{2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathdefault">d</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0651740000000007em;vertical-align:-1.4137769999999998em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000007em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.150216em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span></span></span>代表数据的纬度。</p>
<p>基于欧式距离我们可以把分群的过程描述为一个优化的问题，是一种最小化<strong>群内误差平方和（SSE）<strong>的迭代方法也被称为</strong>群惯性</strong>。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>S</mi><mi>E</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msup><mi>w</mi><mrow><mo>(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo>)</mo></mrow></msup><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msup><mi>x</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>−</mo><msup><mi>μ</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">SSE = \sum^{n}_{i =1 } \sum^{k}_{j=1 } w^{(i,j)}||x^{(i)} - \mu^{(i)}||^{2}_{2} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.2498900000000006em;vertical-align:-1.4137769999999998em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8361130000000006em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>代表样本索引 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span></span></span>代表分群索引</p>
<h2 id="2使用scikit-learn实现k-means方法">2.使用<strong>scikit-learn</strong>实现<strong>K-means</strong>方法</h2>
<hr>
<h3 id="21-创建测试数据并实现算法">2.1 创建测试数据并实现算法</h3>
<p>首先导入所需要的模块：</p>
<pre><code class="language-python"># import module
import numpy as np
from matplotlib import cm
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_samples
</code></pre>
<p>因为二维数据可是简单的绘制在笛卡尔坐标系上，所以生成二维测试数据进行测试：</p>
<pre><code class="language-python"># creat tested data
X, y = make_blobs(n_samples=150, # volume of data 
                  n_features=2, # number of feature 
                  centers=3, # number of centroid
                  cluster_std=0.5,  # distribution of data 
                  shuffle=True,
                  random_state=0)
</code></pre>
<p>绘图查看原始数据：</p>
<pre><code class="language-python"># plot tested data
plt.figure()
plt.scatter(X[:, 0], X[:, 1], c='white', marker='o', edgecolor='black', s=50)
plt.grid()
plt.show()
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://cauliyang.github.io/post-images/1572156791933.png" alt="" loading="lazy"></figure>
<p>从图中可以看出创建的测试数据有明显的分群情况,当然在真实的数据当中原始数据可能没有这么理想。我们先在没有推理的情况下确定<strong>K</strong>的值为3。</p>
<pre><code class="language-python"># k-means
km = KMeans(n_clusters=3, # K value 
            init='random',
            n_init=10, # number of repeatation 
            max_iter=300, 
            tol=1e-4, 
            random_state=0)
# predict labels
y_km = km.fit_predict(X)
</code></pre>
<p>我们进行可视化分群结果：</p>
<pre><code class="language-python">#creating function of ploting graph for reusing 
def plot_res(y_km, X, n_cluster):
    # init colors and markers
    colors = ['lightgreen', 'orange', 'lightblue'][:n_cluster]
    markers = ['s', 'o', 'v'][:n_cluster]

    # plot the cluster to comfirm the result of k-meams by sklearn
    for i, (c, m) in enumerate(zip(colors, markers)):
        plt.scatter(X[y_km == i, 0],
                    X[y_km == i, 1],
                    s=50,
                    c=c,
                    marker=m,
                    edgecolor='black',
                    label=f'cluster {i}')

    # plot centroipd of  different clusters
    plt.scatter(km.cluster_centers_[:, 0],
                km.cluster_centers_[:, 1],
                s=250,
                marker='*',
                c='red',
                edgecolors='black',
                label='centroids')
    # plot lengend
    plt.legend(scatterpoints=1)
    # plot grid
    plt.grid()
    plt.show()

</code></pre>
<figure data-type="image" tabindex="2"><img src="https://cauliyang.github.io/post-images/1572158215803.png" alt="" loading="lazy"></figure>
<p>可以明显看到分群效果十分明显。不过其中还有许多问题：</p>
<ol>
<li>如何确实<strong>K</strong>值</li>
<li>如何评估分群质量</li>
</ol>
<h3 id="22-如何选取k值">2.2 如何选取<strong>K</strong>值</h3>
<p>下面介绍如何使用肘解法选取合适的<strong>K</strong>值，肘解法目的是找出SSE变化幅度最大的<strong>K</strong>值。使用<code>km.inertia_</code> 即可调出<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>S</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">SSE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span>的值。</p>
<pre><code class="language-python">
distortions = []
# test different  numbers of cluster  to  pick up the best K
for i in range(1, 11):
    km = KMeans(n_clusters=i,
                init='k-means++',
                n_init=10,
                max_iter=300,
                random_state=0)

    km.fit(X)
    distortions.append(km.inertia_)

</code></pre>
<p>测试1-11的<strong>K</strong>值选取，并进行可视化查看结果。</p>
<pre><code class="language-python"># plot the tested result for the best K

plt.plot(range(1, 11), distortions, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Distortion')
plt.show()
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://cauliyang.github.io/post-images/1572160740933.png" alt="" loading="lazy"></figure>
<p>从图中我们可以看出在<strong>K</strong>值为3的时候，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>S</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">SSE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span>变化幅度最大，即可得知<strong>K</strong>为3是最优解。</p>
<h3 id="23-如何评估分群的质量">2.3 如何评估分群的质量</h3>
<p>评价聚类质量的一种方法是<strong>轮廓分析</strong>，他可以应用于其他聚类算法，度量其紧密程度。计算轮廓系数的步骤为：</p>
<ol>
<li>计算集群内聚度<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>a</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>，即样本<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">x^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>于集群内所有其他点之间的平均距离。</li>
<li>计算集群与最近集群的分离度<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>b</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">b^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>,即样本<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">x^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>与最近集群内所有样本的平均距离。</li>
<li>计算轮廓系数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>s</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">s^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>，即集群内聚度与集群分离度之差，除以两者中较大的一个。</li>
</ol>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>s</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>=</mo><mfrac><mrow><msup><mi>b</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>−</mo><msup><mi>a</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mrow><mi>max</mi><mo>⁡</mo><mo>{</mo><mrow><msup><mi>b</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo separator="true">,</mo><msup><mi>a</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mo>}</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">s^{(i)} = \frac{b^{(i)} - a^{(i)}}{\max \{{b^{(i)},a^{(i)}}\}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.519em;vertical-align:-0.954em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.565em;"><span style="top:-2.2960000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">max</span><span class="mopen">{</span><span class="mord"><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.814em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.814em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span><span class="mclose">}</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.954em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>轮廓系数的范围在-1到1之间，如果集群分离度和集群内聚度相等，即<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>b</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>=</mo><msup><mi>a</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">b^{(i)}=a^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>。那么轮廓系数为0，如果<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>b</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>&gt;</mo><mo>&gt;</mo><msup><mi>a</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">b^{(i)} &gt;&gt; a^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9270999999999999em;vertical-align:-0.0391em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> 则接近理想的轮廓系数 1 。</p>
<p>可以使用<strong>scikit-learn</strong>中<strong>metric</strong>中的<strong>silhouette_samples</strong>计算样本的轮廓系数。也可以更方便的使用<strong>silhouette_scores</strong>直接计算所有样本的平均轮廓系数。下面显示<strong>K</strong>值基于3的分群结果。</p>
<pre><code class="language-python"># we can use the graph of silhouette to evaluate  result
km = KMeans(n_clusters=3,
            init='k-means++',
            n_init=10,
            max_iter=10,
            tol=1e-04,
            random_state=0)
y_km = km.fit_predict(X)
</code></pre>
<p>绘制轮廓图进行可视化，直观的查看群内轮廓系数。</p>
<pre><code class="language-python"># difining fuction of plot-silhouette for reusing
# plot the graph of silhouette
def plot_sil(y_km, X):
    cluster_lables = np.unique(y_km)
    n_clusters = cluster_lables.shape[0]

    # using function of silhouette in sklearn to get silhouete scores
    silhouette_vals = silhouette_samples(X, y_km, metric='euclidean')

    # plot the graph
    y_ax_lower, y_ax_upper = 0, 0
    yticks = []
    for i, c in enumerate(cluster_lables):
        # get values of  each cluster
        c_silhouette_vals = silhouette_vals[y_km == c] 
        c_silhouette_vals.sort()  # sort value for ploting
        y_ax_upper += len(c_silhouette_vals)
        color = cm.jet(float(i) / n_clusters)
        plt.barh(range(y_ax_lower, y_ax_upper),
                 c_silhouette_vals,
                 height=1.0,
                 edgecolor='none',
                 color=color)
        yticks.append((y_ax_lower + y_ax_upper) / 2)
        y_ax_lower += len(c_silhouette_vals)

    silhouette_avg = np.mean(silhouette_vals)  # get the label of yticks
    plt.axvline(silhouette_avg, color='red',
                linestyle='--')  # plot the avaerage of silhouette
    plt.yticks(yticks, labels=cluster_lables)
    plt.ylabel('Cluster')
    plt.xlabel('Silhouette coefficient')
    plt.show()

</code></pre>
<figure data-type="image" tabindex="4"><img src="https://cauliyang.github.io/post-images/1572162327225.png" alt="" loading="lazy"></figure>
<p>从图中我们可以看出轮廓系数不接近于0，且接近于1表明我们的分群结果良好。且在图中轮廓系数的高度代表群内样本数量，如果样本数量相差太大，说明分群效果不是很好。图中虚线表示平均轮廓系数。</p>
<p>为更好的理解轮廓系数的使用，将<strong>K</strong>值变为2，进行聚类。</p>
<pre><code class="language-python">km = KMeans(
    n_clusters=2,  # value of k has changed 
    init='k-means++',
    n_init=10,
    max_iter=10,
    tol=1e-04,
    random_state=0)
y_km = km.fit_predict(X)
</code></pre>
<p>使用上方作图函数，先观察分群效果。</p>
<figure data-type="image" tabindex="5"><img src="https://cauliyang.github.io/post-images/1572162593247.png" alt="" loading="lazy"></figure>
<p>从图中可以看出分群效果很差，可视化轮廓系数查看结果。</p>
<figure data-type="image" tabindex="6"><img src="https://cauliyang.github.io/post-images/1572162888640.png" alt="" loading="lazy"></figure>
<p>两个群的高度不一致表明分群效果不是很理想，且有的样本轮廓系数极低接近于0。表示分群有很大的问题，需要重新思考<strong>K</strong>值的选取。</p>
<h2 id="3-k-means-from-scratch">3. K-means from scratch</h2>
<p>我们根据算法原理使用<strong>Python</strong>一步步实现<strong>K-means</strong>，首先展示我们所用到的数据集，有关基因在不同条件下处理的表达数据，其中基因数量为样本数量，处理方式为纬度。并且设计为<strong>Terminal</strong>端使用。</p>
<p>终端使用方法为：</p>
<p><code>Usage : python k_mean.py k data max_it (cetroids)</code></p>
<p>其中</p>
<ul>
<li>k_mean.py 为程序脚本</li>
<li>k 为分群数量</li>
<li>data 为原始数据文件</li>
<li>max_it 为最大递归次数</li>
<li>centroids 为初始的质心，用户可以选择提供或者不提供</li>
</ul>
<p>原始数据：</p>
<table>
<thead>
<tr>
<th>gene_expression</th>
<th>treat_1</th>
<th>treat_2</th>
<th>...</th>
</tr>
</thead>
<tbody>
<tr>
<td>g_1</td>
<td>0.2</td>
<td>0.5</td>
<td>...</td>
</tr>
<tr>
<td>g_2</td>
<td>1.4</td>
<td>1.6</td>
<td>...</td>
</tr>
<tr>
<td>...</td>
<td>4.2</td>
<td>2.1</td>
<td>...</td>
</tr>
</tbody>
</table>
<h3 id="31-get-parameters-from-terminal">3.1 Get parameters from terminal</h3>
<p>导入所需的模块</p>
<pre><code class="language-python"># import modules
import sys
import time
import numpy as np
from collections import Counter
from operator import itemgetter
</code></pre>
<p>从终端获取用户传递参数：</p>
<pre><code class="language-python"># defining function for getting parameters from terminal
def get_argv():
    '''
    get the parameters entered by user and return the dictionary parameters
    '''
    # get parameters
    argv_list = sys.argv
    # init parameters
    argv_name = (
        'data',
        'init_cetroids',
        'gene_num',  # numbers of row 
        'ndim',
        'max_it',  # max numbers of  iter
        'k')
    #  determine whether user provide init-centroids according numbers of parameters
    if len(argv_list) == 4:
        # if not provide init-centroid
        _, k, file, max_it = argv_list
        # get information of file
        argv_tuple = get_Cetroid(file, int(k)) + (int(max_it), int(k))
    elif len(argv_list) == 5:
        # if provide init-centroid
        _, k, file, max_it, cetroid_file = argv_list
        # get information
        argv_tuple = get_Cetroid(
            file, int(k), cetroid_file=cetroid_file) + (int(max_it), int(k))
    elif len(argv_list) &lt; 4:
        #  if numbers of parameters is less than  need parameters  then print help
        print('''
            -------------------------------------------------
            Requirement : numpy 

            Usage : python k_mean.py k data max_it (cetroids)

            Result_file : kmeans.out

            Contact : &lt;liyangyang&gt; &lt;yangyangli.vince@gmail.com&gt;

            -------------------------------------------------

            ''')
        sys.exit(0)
    # return dictionary parameters
    return dict(zip(argv_name, argv_tuple))

</code></pre>
<h3 id="32-creating-function-of-report">3.2 Creating function of report</h3>
<pre><code class="language-python"># difining  function of reporting summary 
def summary(kw, tim, kmeanout='kmeans.out'):
    '''
    Create a summary function, count recursive times, run time, etc.。
    '''

    # statistics for each Cluster data
    def print_cluster(kmean=kmeanout):
        # evaluate data
        counter = Counter(np.loadtxt(kmean, dtype=int)[:, 1])
        # produce report
        for clu, num in counter.most_common():
            print(f'    Cluster_{clu} : {num}')

    # creat statistic header
    print('{:-^40}\n'.format('Summary'))
    # print statstic report of each cluster
    print_cluster()
    # print overall information
    print(f'''
    Max_iter_number : {kw['max_it']} 
    Cluster_number  :{kw['k']} 
    Time  : {tim:.2f}s 
    Date  : {time.asctime()}''')
    # creat statistic tial
    print('{:-&lt;40}\n'.format('-'))
</code></pre>
<h3 id="33-calculating-euclidean-distance">3.3 Calculating Euclidean distance</h3>
<pre><code class="language-python"># defining function to calculate Euclidean distance
def eucl_Distance(init_cetroids, piece_data):
    ''' 
    Calculate the Euclidean distance between each data and the centroid
    '''
    distance = np.sqrt(np.sum((init_cetroids - piece_data)**2, axis=1))
    # return euclidean distance
    return distance

</code></pre>
<h3 id="34-getting-centroid-information-and-recursive-function">3.4 Getting centroid information and recursive function</h3>
<pre><code class="language-python">def get_Cetroid(file, k, cetroid_file=None):
    ''' 
    This function is used to get raw data file information: raw data, centroid, data volume, feature dimension
    '''
    # get content of  file
    data = np.loadtxt(file)
    # get information: data volume, feature dimension
    gene_num, ndim = data.shape
    # Determine whether the user provides a centroid, and  randomly if not provided
    if not (cetroid_file):
        # init centroid
        init_cetroids = np.zeros((k, ndim))
        # provied centroid randomly
        for i in range(k):
            index = int(np.random.uniform(0, gene_num))
            init_cetroids[i, :] = data[index, :]
    else:
        # if users provide centroid
        init_cetroids = np.loadtxt(cetroid_file)
    # return information
    return (data, init_cetroids, gene_num, ndim)


    def iter_Cetroid(**argv):
    '''
    Iterative clustering results
    '''
    # get neccessary parameters
    data, init_cetroids, gene_num, ndim, max_it, k = argv.values()
    # init results
    Result = np.zeros((gene_num, 2), dtype=int)
    # grouping data according to Euclidean distance
    for i in range(gene_num):
        # get Euclidean distance
        distance = eucl_Distance(init_cetroids, data[i, :])
        # get the label of shortest distance
        cluster = distance.argmin()
        # grouping
        Result[i, :] = np.array([i, cluster])
    # verify that the results of the iteration are stable and return a new centroid
    Handle, argv['init_cetroids'] = assert_Result(data, init_cetroids, Result,
                                                  k)
    # return informattion
    return Result, Handle.all(), argv, max_it

</code></pre>
<h3 id="35-creating-body-function-and-main-function">3.5 Creating Body function and Main function</h3>
<pre><code class="language-python">def run(arg_dict, it_num=0):
    '''
     the body of  k-means 
    '''
    # perform an iteration and verify that the results are stable
    # then  calculate the new centroid to be returned in dictionary form
    Result, handle, arg_dict, max_it = iter_Cetroid(**arg_dict)
    # determine whether the  condition of end iteration is reached
    if not (handle) and (it_num &lt; max_it):
        # if not reach and the iteration continues
        it_num += 1
        # print numbers of iteration
        print(f'...ing Iter Number :{it_num}')
        # recursive iteration
        run(arg_dict, it_num=it_num)
    # if reach condition
    else:
        # change lable,like change the lables from  0,1,2 to 1,2,3
        Result = Result + 1
        count_1 = Counter(Result[:, 1])
        # save result file
        np.savetxt('kmeans.out', Result, fmt='%d')

def main():
    '''
    the program main function, integrate workflow, and generate reports
    '''
    # get start time
    TIC = time.time()
    # get parameter through terminal
    ARGV = get_argv()
    # running the body function  of k-means
    run(ARGV)
    # get end time
    TOC = time.time()
    # generate report
    summary(ARGV, TOC - TIC)
</code></pre>
<h2 id="4-summary">4. Summary</h2>
<p>本篇文章详细记录两种方式实现<strong>K-means</strong>方法，并且记录如何选取<strong>K</strong>值，如何评估聚类质量。本文最终涉及的代码都会在<a href="https://github.com/cauliyang/Python_book_practice/blob/master/effective_python_practice.ipynb"><strong>Jupyter notebook</strong></a>找到,并且使用<a href="https://github.com/cauliyang/work/tree/master/001_k_mean">脚本程序</a></p>
<p>谢谢观看，欢迎交流！😎</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PCA by Python ]]></title>
        <id>https://cauliyang.github.io/pca-by-python-2/</id>
        <link href="https://cauliyang.github.io/pca-by-python-2/">
        </link>
        <updated>2019-07-19T14:07:56.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>This article documents two methods of PCA analysis using Python, and visualizes 2-dimensional results.</strong></p>
]]></summary>
        <content type="html"><![CDATA[<p><strong>This article documents two methods of PCA analysis using Python, and visualizes 2-dimensional results.</strong></p>
<!-- more -->
<style>
img{
    width: 70%;
    padding-left: 1%;
}
</style>
<h2 id="1intrduction">1.Intrduction</h2>
<h3 id="11-whats-pca">1.1 What's PCA?</h3>
<p>When it comes to methods of reducing dimension, PCA that is an unsupervised linear transformation technique, must be not ignored. Moreover, if you want to know the subtle relationships among data set and reduce the computational complexity in downstream analysis, the PCA may be your best choice! Meanwhile, if you would like to present your data in a 2-dimension or 3-dimension coordinate system, and PCA would sweep your problems!</p>
<p>What is reducing dimension? I will show you an example as follows:</p>
<p>First, suppose you have a five-dimensional data set :</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>1-d</th>
<th>2-d</th>
<th>3-d</th>
<th>4-d</th>
<th>5-d</th>
</tr>
</thead>
<tbody>
<tr>
<td>data-1</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
</tr>
<tr>
<td>data-2</td>
<td>6</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td></td>
</tr>
</tbody>
</table>
<p>Then, you could pick up PC1 and PC2 after PCA to reduce dimension for plotting:</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>PC1</th>
<th>PC2</th>
</tr>
</thead>
<tbody>
<tr>
<td>data-1</td>
<td>0.3</td>
<td>0.6</td>
</tr>
<tr>
<td>data-2</td>
<td>0.1</td>
<td>1.2</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
</tbody>
</table>
<p><strong>PC1</strong> and <strong>PC2</strong> are the result obtained through data is projection on the unit vectors, which enable result to have the most biggest variance(means its distribution is wide) and to be irrelevant(covariance = 0).</p>
<h3 id="12-algorithm">1.2 Algorithm</h3>
<ol>
<li>
<p>Normalize <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">d</span></span></span></span> dimension raw data</p>
</li>
<li>
<p>Creat the covariance matrix</p>
</li>
<li>
<p>Calculate the eigenvalues of the covariance matrix and the corresponding eigenvectors</p>
</li>
<li>
<p>The eigenvectors are sorted in the matrix according to the corresponding feature value, and the first k rows are formed into a matrix <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span>.(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>&lt;</mo><mo>&lt;</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">k&lt;&lt;d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">d</span></span></span></span>)</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>=</mo><mi>x</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">Y = xW</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">x</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span> is the result after reducing dimension to k dimension</p>
</li>
</ol>
<p><strong>Note:</strong> There are two prerequisites for conducting PCA</p>
<ul>
<li>
<p>Raw data has no NA</p>
</li>
<li>
<p>The raw data should be normalized</p>
</li>
</ul>
<h2 id="2-pca-from-scratch">2. PCA from scratch</h2>
<ul>
<li>Importing necessary modules</li>
</ul>
<pre><code class="language-python">import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt 
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
</code></pre>
<ul>
<li>Creating raw data</li>
</ul>
<pre><code class="language-python"># get  data set 
df_wine = pd.read_csv(
    'http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',
    header=None,
    engine='python')
# check data
df_wine.head()
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://cauliyang.github.io/post-images/1572760322010.png" alt="" loading="lazy"></figure>
<ul>
<li>Creating train and test data set</li>
</ul>
<pre><code class="language-python"># creat train and test data set 

X, y = df_wine.iloc[:, 1:], df_wine.iloc[:, 0]

x_train,x_test,y_train,y_test = \
    train_test_split(X,y,test_size = 0.3 , 
                    stratify= y,
                    random_state = 0 )
</code></pre>
<ul>
<li>Standarding the features</li>
</ul>
<pre><code class="language-python"># create standard instance
sc = StandardScaler()
# standard data 
x_train_std = sc.fit_transform(x_train)
x_test_std = sc.fit_transform(x_test)
</code></pre>
<ul>
<li>Creating the covariance matrix and Getting eigenvectors and eigenvalues</li>
</ul>
<p>the calculation of the covriance matrix :</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>σ</mi><mrow><mi>j</mi><mi>k</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo fence="false">(</mo><msubsup><mi>x</mi><mi>j</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup><mo>−</mo><msub><mi>μ</mi><mi>j</mi></msub><mo fence="false">)</mo><mo fence="false">(</mo><msubsup><mi>x</mi><mi>k</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup><mo>−</mo><msub><mi>μ</mi><mi>k</mi></msub><mo fence="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{jk} =  \frac{1}{n} \sum^{n}_{i=1}\bigg(x_{j}^{(i)} - \mu_j\bigg)\bigg(x_{k}^{(i)} - \mu_k\bigg)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size3">)</span></span><span class="mord"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.3986920000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size3">)</span></span></span></span></span></span></p>
<p>Then, using <code>numpy.cov</code> and <code>numpy.linalg.eig</code> to get the covariance matrix and eigenvectors respectively</p>
<pre><code class="language-python"># calculate the covariance matrix 
cov_mat = np.cov(x_train_std.T)
# Getting eigenvectors and eigenvalues
eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)
</code></pre>
<p><strong>NOTE:</strong> there are 13 eigenvectors totally, the number of eigenvalues might be not as same as the number of features sometimes.</p>
<p>Firstly, plotting the Variance interpretation ratio, which is obtained through eigenvalue <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\lambda_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> divided by the sum of all the eigenvalues:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><msub><mi>λ</mi><mi>j</mi></msub><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><msub><mi>λ</mi><mi>j</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\lambda_j}{\sum^d_{j=1}\lambda_j}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.686266em;vertical-align:-1.314826em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.120992em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9890079999999999em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.314826em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<pre><code class="language-python"># get sum of all the eigenvalues
tot = sum(eigen_vals)
# get variance interpretation ratio
var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]
cum_var_exp = np.cumsum(var_exp)
</code></pre>
<p>Besides, plotting the result to get in-depth understanding:</p>
<pre><code class="language-python">plt.figure() # creat plot
# creat bar plot
plt.bar(
    range(1, 14),
    var_exp,
    alpha=0.5,
    label='individual explained variance',
)
# creat step plot 
plt.step(range(1, 14),
         cum_var_exp,
         where='mid',
         label='cumulative explained variance')
# add label 
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal component index')
# add legend
plt.legend(loc='best')
# save picture
plt.savefig('pca_index.png', format='png', bbox_inches='tight', dpi=300)
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://cauliyang.github.io/post-images/1572764173795.png" alt="" loading="lazy"></figure>
<p>We can conclude that <strong>PC1</strong> only takes account for about 40%. Furthermore, the sum of <strong>PC1</strong> and <strong>PC2</strong> have 60% variance.</p>
<ul>
<li>Selecting the first <strong>k</strong> values to form matrix <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span></li>
</ul>
<pre><code class="language-python"># integrate eigenvalues  and eigenvectors 
eigen_paris = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])
               for i in range(len(eigen_vals))]
# sort according to eigenvalues 
eigen_paris.sort(key=lambda x: x[0], reverse=True)
# pick up the first 2 eigenvalues 
w = np.hstack(
    [eigen_paris[0][1][:, np.newaxis], eigen_paris[1][1][:, np.newaxis]])
# check matrix x 
w
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://cauliyang.github.io/post-images/1572766213478.png" alt="" loading="lazy"></figure>
<ul>
<li>Tranforming raw data</li>
</ul>
<pre><code class="language-python"># reduce dimension 
x_train_pca = x_train_std.dot(w)
# check resulted data 
x_train_pca.shape
</code></pre>
<p><code>(124, 2)</code></p>
<p>Then plotting the result and putting the label in terms of original info, but keeping in mind PCA is unsupervised learning skill without labels</p>
<pre><code class="language-python"># init colors and markers 
colors = ['r', 'b', 'g']
markers = ['s', 'x', 'o']
# plot scatter
for l, c, m in zip(np.unique(y_train), colors, markers):
    plt.scatter(x_train_pca[y_train == l, 0],
                x_train_pca[y_train == l, 1],
                c=c,
                label=1,
                marker=m)
# add label and legend 
plt.xlabel('PC 1')
plt.ylabel('PC 2')
plt.legend(loc='lower left')
plt.savefig('distribution.png', format='png', bbox_inches='tight', dpi=300)

</code></pre>
<figure data-type="image" tabindex="4"><img src="https://cauliyang.github.io/post-images/1572766761786.png" alt="" loading="lazy"></figure>
<h2 id="3-pca-by-scikit-learn">3. PCA by  scikit-learn</h2>
<p>we can  conduct PCA easily by <strong>sklearn</strong></p>
<ul>
<li>Importing modules</li>
</ul>
<pre><code class="language-python">from sklearn.decomposition import PCA
from matplotlib.colors import ListedColormap
from sklearn.linear_model import LogisticRegression
</code></pre>
<ul>
<li>Defining  function of plot_decision_region</li>
</ul>
<pre><code class="language-python">
def plot_dicision_regions(X, y, classifier, resolution=0.02):
    # init markers and colors 
    markers = ('s', 'x', 'o', '^', 'v')
    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
    cmap = ListedColormap(colors[:len(np.unique(y))])
    # creat info for plot region
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
                           np.arange(x2_min, x2_max, resolution))
    # test classifier's accurate 
    z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
    z = z.reshape(xx1.shape)
    # plot desicion region 
    plt.contourf(xx1, xx2, z, alpha=0.4, cmap=cmap)
    # set x,y length
    plt.xlim(xx1.min(), xx1.max())
    plt.ylim(xx2.min(), xx2.max())
    # plot result 
    for idx, cl in enumerate(np.unique(y)):
        plt.scatter(
            x=X[y == cl, 0],
            y=X[y == cl, 1],
            alpha=0.6,
            color=cmap(idx),
            edgecolor='black',
            marker=markers[idx],
            label=cl,
        )
</code></pre>
<ul>
<li>PCA by sklearn</li>
</ul>
<pre><code class="language-python"># creat pca instance 
pca = PCA(n_components = 2 )
# creat classifier instance 
lr = LogisticRegression()
# reduce dimension for  data set 
x_train_pca = pca.fit_transform(x_train_std)
x_test_pca  = pca.transform(x_test_std)
# classify x_train_pca 
lr.fit(x_train_pca,y_train)
# plot dicision region
plot_dicision_regions(x_train_pca,y_train,classifier=lr)
# add info
plt.xlabel('PC 1')
plt.ylabel('PC 2')
plt.legend(loc='lower left')
plt.show()
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://cauliyang.github.io/post-images/1572767868782.png" alt="" loading="lazy"></figure>
<p>We can see that the classifier's accurate is excellent according to actual labels</p>
<p><strong>TIPS</strong>:</p>
<p>You can set <code>n_components = None</code>, and the result would retain all principle components. Moreover, you could call <code>explained_variance_ration_</code> to use variance explanation ratio.</p>
<h2 id="3summary">3.Summary</h2>
<p>All the above are the main content, welcome everybody communicates with me! 🤠</p>
<p><strong>Reference book :</strong> <a href="https://www.amazon.com/dp/B0742K7HYF/ref=sr_1_1?__mk_zh_CN=%E4%BA%9A%E9%A9%AC%E9%80%8A%E7%BD%91%E7%AB%99&amp;crid=27TEKOK8R4TOR&amp;keywords=python+machine+learning+sebastian+raschka&amp;qid=1572770147&amp;s=digital-text&amp;sprefix=python+machine++learning+seb%2Cdigital-text%2C389&amp;sr=1-1">Python marchine learning</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Blog Ideas ]]></title>
        <id>https://cauliyang.github.io/bo-ke-xiang-fa/</id>
        <link href="https://cauliyang.github.io/bo-ke-xiang-fa/">
        </link>
        <updated>2019-05-09T00:46:16.000Z</updated>
        <summary type="html"><![CDATA[<p>This Blog record learning process, welcome everyone to communicate with me!😊</p>
]]></summary>
        <content type="html"><![CDATA[<p>This Blog record learning process, welcome everyone to communicate with me!😊</p>
<!-- more -->
<h1 id="ideas">Ideas</h1>
<p>This blog is used as a public note to record my learning process. I also hope to help others~.</p>
<p>If you have an infringement problem, then you can contact me. if it is true ,I will delete it immediately.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[About ]]></title>
        <id>https://cauliyang.github.io/about/</id>
        <link href="https://cauliyang.github.io/about/">
        </link>
        <updated>2019-01-25T11:09:48.000Z</updated>
        <content type="html"><![CDATA[<p>My name is Yangyang Li , I would like to take advantage of mathematics and programming to change the world and detect the secrets of life, welcome everybody to communicate with me!  🤓</p>
]]></content>
    </entry>
</feed>