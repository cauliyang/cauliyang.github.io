<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CUDA on Bytes of Life</title><link>https://yangyangli.top/tags/cuda/</link><description>Recent content in CUDA on Bytes of Life</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>2023 &lt;a class='hover:underline hover:decoration-primary-400 hover:text-primary-500' href=https://yangyangli.top target=_blank rel='noopener noreferrer'>Yangyang Li&lt;/a></copyright><lastBuildDate>Tue, 29 Aug 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://yangyangli.top/tags/cuda/index.xml" rel="self" type="application/rss+xml"/><item><title>CUDA for Deep Learning Inference in Rust and C++</title><link>https://yangyangli.top/posts/022-cuda-configuration-for-rust-and-cpp/</link><pubDate>Tue, 29 Aug 2023 00:00:00 +0000</pubDate><guid>https://yangyangli.top/posts/022-cuda-configuration-for-rust-and-cpp/</guid><description>1. Deep Learning Inference # Currently, both Rust and C++ are emerging as noteworthy contenders in the realm of deep learning, primarily due to their efficiency despite Python&amp;rsquo;s prevailing dominance in model training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://yangyangli.top/posts/022-cuda-configuration-for-rust-and-cpp/featured.jpg"/></item></channel></rss>